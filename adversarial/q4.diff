diff -u bl/attack.py q4/attack.py
--- bl/dataset.py	2020-04-24 00:24:09.592576366 +0800
+++ q4/dataset.py	2020-04-24 00:24:43.139929368 +0800
@@ -17,18 +18,17 @@
 
     def generate_graph(self, pre_noise, x, groundTruth, target=None):
         noise = 10 * tf.tanh(pre_noise)
         x_noise = x + noise  
         x_clip = tf.clip_by_value(x_noise, 0, 255)
         x_round = x_clip + tf.stop_gradient(x_clip // 1 - x_clip)
         x_norm = (x_round - mean) / (std + 1e-7)  
         logits = self.model.build(x_norm) 
         preds = tf.nn.softmax(logits) 
-        gt_one_hot = tf.one_hot(groundTruth, config.nr_class)
         if target != None:
             target_one_hot = tf.one_hot(target, config.nr_class)
         else:
             target_one_hot = tf.one_hot(groundTruth, config.nr_class)
 
-        loss = tf.losses.softmax_cross_entropy(target_one_hot, logits) * (-1) 
+        loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=target_one_hot, logits=logits))
         acc = tf.reduce_mean(tf.cast(tf.equal(tf.cast(tf.argmax(preds, 1), dtype=tf.int32),
-                                              tf.cast(tf.argmax(gt_one_hot, 1), dtype=tf.int32)), tf.float32))
+                                              tf.cast(tf.argmax(target_one_hot, 1), dtype=tf.int32)), tf.float32))
         return acc, loss, x_round
 
     '''Build a graph for evaluating the classification result of adversarial examples'''
--- bl/dataset.py	2020-04-24 00:24:09.592576366 +0800
+++ q4/dataset.py	2020-04-24 00:24:43.139929368 +0800
@@ -37,10 +45,10 @@
 
     data = tf.placeholder(tf.float32, shape=(config.minibatch_size,) + config.image_shape, name='data')
     label = tf.placeholder(tf.int32, shape=(None,), name='label')  # placeholder for targetted label
 
-    pre_noise = tf.Variable(tf.nn.sigmoid(tf.random_uniform((1, 32, 32, 3), -3, 3)))
+    pre_noise = tf.Variable(tf.zeros([1, 32, 32, 3], dtype=tf.float32))
     vgg16 = Vgg16()
     attack = Attack(vgg16, config.minibatch_size)
     acc, loss, adv = attack.generate_graph(pre_noise, data, groundTruth, label)
-    acc_gt = attack.evaluate(data, groundTruth)
+    acc_gt = attack.evaluate(data, label)
 
     placeholders = {
         'data': data,
@@ -60,11 +68,12 @@
     tf.set_random_seed(12345)  # ensure consistent results
     succ = 0
     noise_l2 = 0
-    with tf.Session() as sess:
+    target = np.array([7])
+    with tf.Session(config=configTf) as sess:
         # print(train_set.minibatches)
+        sess.run(tf.global_variables_initializer())  # init all variables
         for idx in range(train_set.minibatches):
             global_cnt = 0
-            sess.run(tf.global_variables_initializer())  # init all variables
             images, labels = sess.run(train_batch_gnr)
             for epoch in range(1, config.nr_epoch + 1):
                 global_cnt += 1
                 feed_dict = {
                     placeholders['data']: images,
-                    placeholders['label']: labels,
+                    placeholders['label']: target,
                     placeholders['groundTruth']: labels,
                 }
                 _, accuracy, loss_batch, adv_examples = sess.run([train, acc, loss, adv],
                                                                  feed_dict=feed_dict)
 
@@ -84,6 +93,6 @@
 
             output_img(x=adv_examples, out_path='./out/adv_examples/{}.png'.format(idx)) 
             accuracy_gt = acc_gt.eval(
-                feed_dict={placeholders['data']: adv_examples, placeholders['groundTruth']: labels}) 
+                feed_dict={placeholders['data']: adv_examples, placeholders['label']: target}) 
             succ = (idx * succ + 1 - accuracy_gt) / (idx + 1)
             noise_l2 = (idx * (noise_l2) + ((adv_examples - images)) ** 2) / (idx + 1)
             print('Success rate of this attack is {}'.format(succ))
